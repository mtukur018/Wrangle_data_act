{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                     Reporting: wragle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data wrangling is the process of gathering your data, assessing its quality and structure, and cleaning it \n",
    "before you do things like analysis, visualization, or build predictive models using machine learning. \n",
    "I will be wrangling,analyzing and visualizing three(3)datasets,They are tweet archive from Twitter \n",
    "user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs \n",
    "with a humorous comment about the dog.the three datasets are listed below;\n",
    "\n",
    "- A downloaded (twitter_archive_enhanced.csv) from the WeRateDogs Twitter archive data\n",
    "- downloaded (image_predictions.tsv) from Udacity Servers \n",
    "- A tweet_json.txt file generated from twitter ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below are the steps i took in wrangling my datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Gathering data\n",
    "2. Assessing data\n",
    "3. Cleaning data\n",
    "4. Storing data\n",
    "5. Analyzing, and visualizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ``Gathering Datasets`` \n",
    "The data used for this project consisted of three different datasets that were obtained as following:\n",
    "twitter_archive_enhanced.csv : This dataset was provided in the project workspace . I downloaded it by \n",
    "clicking on the link, I then uploaded it in my Project workspace and read it into pandas dataframe.i.e ``twt_data=pd.read_csv('twitter-archive-enhanced.csv')``\n",
    "\n",
    "- Tweet image prediction file: I imported the Python requests, numpy and os libraries. With the get()function of the requests library, I got the data through its url and saved it in to a variable name ``sample_img_data``. using the open function.\n",
    "\n",
    "\n",
    "- Tweet_Json text: I created a twitter developer account and sent to request to Twitter, It has not been \n",
    "granted yet so I had to used the Tweet_Json text file provided by Udacity to work with. I uploaded it to my Udacity Workspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assessing Data\n",
    "I assessed the data using the following technique:\n",
    "Visually: I read the three different dataframes individually in a jupiter notebook.\n",
    "Programmatically: I did various programmatic assessment with various python and pandas methods and \n",
    "functions such as .info(),.columns , .describe() , .duplicated() , .sum() , .sample() , "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cleaning Data\n",
    "Before performing the cleaning , I made a copy of each databsets with the copy method, then data Cleaning processes to Define, Code and Test. which processes were followed in cleaning the data. also proceed to check for quality issues and tidiness. which were listed below\n",
    "\n",
    "### Quality issues\n",
    "1. twt_data: Timestap columns is an object type instead of datetime.  \n",
    "\n",
    "2. twt_data: tweet id column datatype displays int64 instead,it should be an object \n",
    "\n",
    "\n",
    "3. twt_sample_img: columns such as ('p1', 'p2', 'p1_config', 'p2_config'. etc.) dont have descriptive titles.\n",
    "\n",
    "4. twt_json: the id should have the same name as tweet_id for consistency when merging the datasets.\n",
    "\n",
    "5. twt_data: Columns ('doggo', 'puppo', 'floofer, 'pupper') has None for missing Values.\n",
    "\n",
    "6. twt_data: 'Names' columns has None values instead of 'NAN' and too many invalid values.\n",
    "\n",
    "7. there are 181 retweets as showed by retweeted_status_id\n",
    "\n",
    "8. twt_data: Name columns consists of names with upper case letters. \n",
    "9. Rating numerators less than 10 should be looked into\n",
    "\n",
    "### Tidiness issues\n",
    "- twt_csv and twt_json should be merged in twt_csv\n",
    "\n",
    "- twt_csv(twt_data):  the columns ``('doggo', 'floofer', 'pupper', 'puppo')`` should be merge in a single column for better analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Storing the Data\n",
    "After gathering, assessing and cleaning the data, I saved the merged data in a csv file named \n",
    "twitter_archive_master,csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in conclusion this project has guide me how to use the wrangling process in analyzing data, and with further practice i believe i can get more insight in data wrangling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
